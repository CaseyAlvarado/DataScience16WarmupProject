{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from patsy import dmatrices\n",
    "from sklearn import datasets, svm\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration: Linear regression tries to approxmate coefficients of a linear equation. I am curious to find out if changing the model to fit an equation to the data, but not neccsarily a linear one --how that would affect the results. This is how I uncovered the Support Vector Machine \"SVM\". SVM tries to take the data to another plane, not the normal 2D plane, and tries to find a line in that plane that seperates the data into two groups by tunning the parameters to the equation. \n",
    "\n",
    "Online I read the iPython Notebook Tutoral for Titanic: Machine Learning from Distaster. https://www.kaggle.com/c/titanic/forums/t/5105/ipython-notebook-tutorial-for-titanic-machine-learning-from-disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas of my own that I am incorporating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_train = pandas.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for null values in the data\n",
    "titanic_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, the sums above tell us that there are multiple null values. We can now clean the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "titanic_train[\"Age\"] = titanic_train[\"Age\"].fillna(titanic_train[\"Age\"].median())\n",
    "print titanic_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cabin is null we will not worry about because a lot of the data is missing so we cannot really fill it in. Plus if we tried we cannot replace null with the median because ths column has strings not integers to take the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "# Find all the unique genders -- the column appears to contain only male and female.\n",
    "print(titanic_train[\"Sex\"].unique())\n",
    "\n",
    "# Replace all the occurences of female with the number 1.\n",
    "titanic_train.loc[titanic_train[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_train.loc[titanic_train[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "# Find all the unique values for \"Embarked\".\n",
    "print(titanic_train[\"Embarked\"].unique())\n",
    "\n",
    "titanic_train.loc[titanic_train[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_train.loc[titanic_train[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_train.loc[titanic_train[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "titanic_train.loc[titanic_train[\"Embarked\"].isnull(), \"Embarked\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex  Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0   22      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1   38      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1   26      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1   35      1      0   \n",
       "4                           Allen, Mr. William Henry   0   35      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  \n",
       "0         A/5 21171   7.2500   NaN        0  \n",
       "1          PC 17599  71.2833   C85        1  \n",
       "2  STON/O2. 3101282   7.9250   NaN        0  \n",
       "3            113803  53.1000  C123        0  \n",
       "4            373450   8.0500   NaN        0  "
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an acceptable formula for the machine learning algorithms\n",
    "formula_ml = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp + Parch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "print len(titanic_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we are submitting all of the data into matrices with the suggested formula above. The formula above is the general equation that the algorithm will try to fit and predict the coefficients for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, x = dmatrices(formula_ml, data=titanic_train, return_type='matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not really sure what the features are, I read some documentation that explained that they were the training vectors since SVM works with vectors in hypoerplanes. The documentation link is here: http://scikit-learn.org/stable/modules/svm.html#svr '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select which features we would like to analyze\n",
    "# try chaning the selection here for diffrent output.at \n",
    "# Choose : [2,3] - pretty sweet DBs [3,1] --standard DBs [7,3] -very cool DBs,\n",
    "# [3,6] -- very long complex dbs, could take over an hour to calculate! \n",
    "feature_1 = 7\n",
    "feature_2 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 1 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-493-b6a4cc4f44ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 7 is out of bounds for axis 1 with size 7"
     ]
    }
   ],
   "source": [
    "X = np.asarray(x)\n",
    "X = X[:,[feature_1, feature_2]]  \n",
    "\n",
    "\n",
    "y = np.asarray(y)\n",
    "\n",
    "\n",
    "# needs to be 1 dimenstional so we flatten. it comes out of dmatirces with a shape. \n",
    "y = y.flatten()      \n",
    "\n",
    "print len(X)\n",
    "print len(y)\n",
    "n_sample = len(X)\n",
    "\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all of this data of information but we want to only use 90% for training the remaining for test, so we split that up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "\n",
    "\n",
    "X_train = X[:.9 * n_sample]\n",
    "y_train = y[:.9 * n_sample]\n",
    "X_test = X[.9 * n_sample:]\n",
    "y_test = y[.9 * n_sample:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM works by plotting points in many different planes, like linear and polynomial, and using the same policies and ways to find the coefficient as it would as if it were linear. It is just tricking it into thinking it is linear in that hypoerplane and then it can see which data points are clumped and tries to draw a line between a clear division and use that as the line coefficients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This below normally produced some cool graphs, but basically it is developing an SVM for each type of kernel model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# types of models to fit\n",
    "types_of_kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(types_of_kernels):\n",
    "    clf = svm.SVC(kernel=kernel, gamma=3)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    plt.figure(fig_num)\n",
    "    plt.scatter(X[:, 0], X[:, 1])\n",
    "\n",
    "    # circle out the test data\n",
    "    plt.scatter(X_test[:, 0], X_test[:, 1])\n",
    "    \n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.pcolormesh(XX, YY, Z > 0)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "               levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.title(kernel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to use this algorithm on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test = pandas.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning test data first by removing the null values in the age column. I am not planning to use embarked since in my previous iteration, it did not have too much of an effect on the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic_test[\"Age\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where things start to go sour. The formula defines the variables we want to be fitted to an equation. The survived column does not exist in the test data, so it was angry at the Survived column in the formula. Beyond that, later when trying to convert back into a csv and tracking the data along the way, part of the data is lost. The x data and y target matrices become different lengths and they only have the first 91 of the data. It was weird and I couldn't figure out the length issue so I moved on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an acceptable formula for the machine learning algorithms\n",
    "formula_ml = 'Survived ~ C(Pclass) + C(Sex) + Age + SibSp + Parch'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Here you can output which ever result you would like by changing the Kernel and clf.predict lines\n",
    "# Change kernel here to poly, rbf or linear\n",
    "# adjusting the gamma level also changes the degree to which the model is fitted\n",
    "clf = svm.SVC(kernel='poly', gamma=3).fit(X_train, y_train)                                                            \n",
    "y,x = dmatrices(formula_ml, data=titanic_test, return_type='dataframe')\n",
    "\n",
    "# Change the interger values within x.ix[:,[6,3]].dropna() explore the relationships between other \n",
    "# features. the ints are column postions. ie. [6,3] 6th column and the third column are evaluated. \n",
    "res_svm = clf.predict(x.ix[:,[1,3]].dropna()) \n",
    "\n",
    "res_svm = DataFrame(res_svm,columns=['Survived'])\n",
    "res_svm.to_csv(\"data.csv\") # saves the results for you, change the name as you please. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from sklearn import svm\n",
    "\n",
    "y, x = dmatrices(formula_ml, data=titanic_train, return_type='matrix')\n",
    "X = np.asarray(x)\n",
    "\n",
    "\n",
    "y = np.asarray(y)\n",
    "print len(X)\n",
    "print len(y)\n",
    "# X = [[0, 0], [1, 1]]\n",
    "# y = [0, 1]\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines definitely did not work for me. It chopped off a lot of my data. For some reason, they just took my data. Perhaps this was a problem with my understanding from the problem. I understood generally how SVMS worked on a high level by readiing a lot of math resources like these: http://dustwell.com/PastWork/IntroToSVM.pdf, https://en.wikipedia.org/wiki/Support_vector_machine, and http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf. In theory, this seems like a cool idea. This is where I would have wanted my model to go. I think that expanding out into higher planes until the data aggregates itself into clumps, away from each other is more natural. However, now, I will try Regresson Trees from the data Science Quest Tutorial. https://www.kaggle.com/c/titanic/details/getting-started-with-random-forests. I will continue with the tutorial online from last time and then expand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is all from the previous tutorial. First we clean the data by dropping all nulls. Then we transfer the values under \"Sex\" into 0 if male and 1 if female. Additionally, we identify all the possible column variables we could use to identify the target under predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name Sex  Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris   0   22      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1   38      1      0   \n",
      "2                             Heikkinen, Miss. Laina   1   26      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1   35      1      0   \n",
      "4                           Allen, Mr. William Henry   0   35      0      0   \n",
      "5                                   Moran, Mr. James   0   28      0      0   \n",
      "6                            McCarthy, Mr. Timothy J   0   54      0      0   \n",
      "7                     Palsson, Master. Gosta Leonard   0    2      3      1   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   1   27      0      2   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)   1   14      1      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        0  \n",
      "1          PC 17599  71.2833   C85        1  \n",
      "2  STON/O2. 3101282   7.9250   NaN        0  \n",
      "3            113803  53.1000  C123        0  \n",
      "4            373450   8.0500   NaN        0  \n",
      "5            330877   8.4583   NaN        2  \n",
      "6             17463  51.8625   E46        0  \n",
      "7            349909  21.0750   NaN        0  \n",
      "8            347742  11.1333   NaN        0  \n",
      "9            237736  30.0708   NaN        1  \n"
     ]
    }
   ],
   "source": [
    "titanic_train[\"Age\"] = titanic_train[\"Age\"].fillna(titanic_train[\"Age\"].median())\n",
    "\n",
    "# Replace all the occurences of female with the number 1.\n",
    "titanic_train.loc[titanic_train[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_train.loc[titanic_train[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "# The columns we'll use to predict the target\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "print titanic_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820426487093\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic_train[predictors], titanic_train[\"Survived\"], cv=3)\n",
    "\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From last time, with the Random Forest tree model, I found the mean score to be 0.82.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataQuest tutorial mentioned a really interesting consideration: title length. The majority of the people did not have titles next to their name, but that might have been because they were socially unimportant. If they did have titles next to their name, then their chances of survival increased significantly because they were highly regarded enough so that they could have gotten put on a boat before other people of lower classes. Therefore, the length of their title will become a recode in the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr          517\n",
      "Miss        182\n",
      "Mrs         125\n",
      "Master       40\n",
      "Dr            7\n",
      "Rev           6\n",
      "Col           2\n",
      "Major         2\n",
      "Mlle          2\n",
      "Countess      1\n",
      "Ms            1\n",
      "Lady          1\n",
      "Jonkheer      1\n",
      "Don           1\n",
      "Mme           1\n",
      "Capt          1\n",
      "Sir           1\n",
      "Name: Name, dtype: int64\n",
      "1     517\n",
      "2     183\n",
      "3     125\n",
      "4      40\n",
      "5       7\n",
      "6       6\n",
      "7       5\n",
      "10      3\n",
      "8       3\n",
      "9       2\n",
      "Name: Name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic_train[\"Name\"].apply(get_title)\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "titanic_train[\"Title\"] = titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsing of the names is done with a regular expression that scans the Name column for a title. Interestingly, there are more males of high class than females. This could perhaps be because even though more girls of class could have been on the boat but the document where they pulled this information from might only have these names. Additionally, women were probably just considered a +1 to their husbands during those times.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My logic included that if women had children on the boat, then in order to save the children, they might throw the child on the boat to save the child. The people around them might also include the mother so that she could protect the child. The data provides the information of siblings and sprouses onboard as well as number of family or children. We can combine these numbers into a category that tells us how many family members each person had on board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_train[\"FamilySize\"] = titanic_train[\"SibSp\"] + titanic_train[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic_train[\"NameLength\"] = titanic_train[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what are lambda functions? they are cool. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made a new column in the training data to insert this summation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can find out what are the best features in this data set of predictors. Scikit learn has a function that informs you which factors have the greatest income on the results. They probably run some version of Pearson's or Spearman's correlation algorithms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAEsCAYAAAAIBeLrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHRFRkYR2RERF/j8LguQdfpvEaQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f73f403d110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811447811448\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\", \"FamilySize\", \"Title\"]\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic_train[predictors], titanic_train[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores.  See how \"Pclass\", \"Sex\", \"Title\", and \"Fare\" are the best?\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Pick only the four best features.\n",
    "predictors = [\"Pclass\", \"Sex\", \"Fare\", \"Title\"]\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic_train[predictors], titanic_train[\"Survived\"], cv=3)\n",
    "\n",
    "print (scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph, it looks like sex, title, class, and fare are the most distinct factors in determining if a person will live or die. Therefore I will add more weight to these data columns before predicting again. I think that wealthy-ness can be combined into one big category. I think the components of this big category include Pclass, Fare, and Title. Where I think Pclass should have Title should have the highest coefficient because of the rarity of having their names. If a person does not have Title next to their name and this column will just be left be blank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "titanic_train[\"SocialClass\"] = 2*titanic_train[\"Pclass\"] + 1*titanic_train[\"Fare\"] + 3*titanic_train[\"Title\"].convert_objects(convert_numeric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>SocialClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>16.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>82.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>19.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>64.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>17.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name Sex  Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris   0   22      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...   1   38      1      0   \n",
       "2                             Heikkinen, Miss. Laina   1   26      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)   1   35      1      0   \n",
       "4                           Allen, Mr. William Henry   0   35      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked Title  FamilySize  NameLength  \\\n",
       "0         A/5 21171   7.2500   NaN        0     1           1          23   \n",
       "1          PC 17599  71.2833   C85        1     3           1          51   \n",
       "2  STON/O2. 3101282   7.9250   NaN        0     2           0          22   \n",
       "3            113803  53.1000  C123        0     3           1          44   \n",
       "4            373450   8.0500   NaN        0     1           0          24   \n",
       "\n",
       "   SocialClass  \n",
       "0      16.2500  \n",
       "1      82.2833  \n",
       "2      19.9250  \n",
       "3      64.1000  \n",
       "4      17.0500  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predictors can be updated to eliminate Fare, Title, and Pclass instead include one large big category called \"Social Class\" referring to just what class they were in socially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictors = [\"SocialClass\", \"Sex\", \"Age\", \"FamilySize\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test = pandas.read_csv('test.csv'); \n",
    "titanic_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now acquiring test data and cleaning it. Replacing any nan numbers in age and social class with the mean of the other values. Changing the sex column to be integer instead of string. Additionally, same code as above, checking and calculating titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test[\"Age\"] = titanic_test[\"Age\"].fillna(titanic_test[\"Age\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace all the occurences of female with the number 1.\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Sex\"] == \"female\", \"Sex\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "titanic_test.loc[titanic_test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "titanic_test.loc[titanic_test[\"Embarked\"].isnull(), \"Embarked\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr        240\n",
      "Miss       78\n",
      "Mrs        72\n",
      "Master     21\n",
      "Col         2\n",
      "Rev         2\n",
      "Dona        1\n",
      "Ms          1\n",
      "Dr          1\n",
      "Name: Name, dtype: int64\n",
      "1       240\n",
      "2        79\n",
      "3        72\n",
      "4        21\n",
      "7         2\n",
      "6         2\n",
      "Dona      1\n",
      "5         1\n",
      "Name: Name, dtype: int64\n",
      "<type 'int'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# A function to get the title from a name.\n",
    "def get_title(name):\n",
    "    # Use a regular expression to search for a title.  Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = titanic_test[\"Name\"].apply(get_title)\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "print(pandas.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "titanic_test[\"Title\"] = titles\n",
    "print type(titanic_test[\"Title\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test[\"FamilySize\"] = titanic_test[\"SibSp\"] + titanic_test[\"Parch\"]\n",
    "\n",
    "# The .apply method generates a new series\n",
    "titanic_test[\"NameLength\"] = titanic_test[\"Name\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NameLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name Sex  \\\n",
       "0          892       3                              Kelly, Mr. James   0   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)   1   \n",
       "2          894       2                     Myles, Mr. Thomas Francis   0   \n",
       "3          895       3                              Wirz, Mr. Albert   0   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   1   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked Title  FamilySize  \\\n",
       "0  34.5      0      0   330911   7.8292   NaN        2     1           0   \n",
       "1  47.0      1      0   363272   7.0000   NaN        0     3           1   \n",
       "2  62.0      0      0   240276   9.6875   NaN        2     1           0   \n",
       "3  27.0      0      0   315154   8.6625   NaN        0     1           0   \n",
       "4  22.0      1      1  3101298  12.2875   NaN        0     3           2   \n",
       "\n",
       "   NameLength  \n",
       "0          16  \n",
       "1          32  \n",
       "2          25  \n",
       "3          16  \n",
       "4          44  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where my intution is telling me that title should have a larger weight than the others because of the rarity it is to have their information. Then I think that Pclass should be weighted the second highest because where you slept on a boat and who you socialized with was a big deal, welathier people would hang out together. Fare was weighted the lowest because well perhaps someone could have bought someone else's ticket. It is still really important, but Title and Pclass are slightly more important. This could be dangerous because this could lead to overfitting so caution is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/casey/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "titanic_test[\"SocialClass\"] = 0.5*titanic_test[\"Pclass\"] + 1*titanic_test[\"Fare\"] + 2*titanic_test[\"Title\"].convert_objects(convert_numeric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>NameLength</th>\n",
       "      <th>SocialClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>11.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>14.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>12.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>12.1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>19.7875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name Sex  \\\n",
       "0          892       3                              Kelly, Mr. James   0   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)   1   \n",
       "2          894       2                     Myles, Mr. Thomas Francis   0   \n",
       "3          895       3                              Wirz, Mr. Albert   0   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   1   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked Title  FamilySize  \\\n",
       "0  34.5      0      0   330911   7.8292   NaN        2     1           0   \n",
       "1  47.0      1      0   363272   7.0000   NaN        0     3           1   \n",
       "2  62.0      0      0   240276   9.6875   NaN        2     1           0   \n",
       "3  27.0      0      0   315154   8.6625   NaN        0     1           0   \n",
       "4  22.0      1      1  3101298  12.2875   NaN        0     3           2   \n",
       "\n",
       "   NameLength  SocialClass  \n",
       "0          16      11.3292  \n",
       "1          32      14.5000  \n",
       "2          25      12.6875  \n",
       "3          16      12.1625  \n",
       "4          44      19.7875  "
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the title, Fare, and Pclass fields in the predictors. Replacing it with SocialClass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors_w_SocialClass= [\"Sex\", \"Age\", \"FamilySize\", \"SocialClass\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_test[\"SocialClass\"] = titanic_test[\"SocialClass\"].fillna(titanic_test[\"SocialClass\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test[\"SocialClass\"].dropna().isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My second theory is that like in the movie, the people will try to save all of the children first. However, if they see that the child could go without a mother, then they might throw the mother on the boat. I think small families with a lot of women and children have the greatest chance of surviving. That's why I wanted to weigh S differently. If the women had 2 other parent or children members, then their integer stored in 1 would scale by the number of parent or children they had. This kind of means that if they are female, it's not just them, it's them and they are children that will try to go together.\n",
    "This would not work for men. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_train.loc[((titanic_train[\"Sex\"] == 1) & (titanic_train[\"Parch\"] ==3)), \"Sex\"] = titanic_train[\"Sex\"]* 3\n",
    "titanic_train.loc[((titanic_train[\"Sex\"] == 1) & (titanic_train[\"Parch\"] >=4)), \"Sex\"] = 4* titanic_train[\"Sex\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79124579  0.84848485  0.81144781]\n",
      "0.817059483726\n"
     ]
    }
   ],
   "source": [
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "alg.fit(titanic_train[predictors_w_SocialClass], titanic_train[\"Survived\"])\n",
    "titanic_test[predictors_w_SocialClass].isnull().sum()\n",
    "predictions = alg.predict(titanic_test[predictors_w_SocialClass])\n",
    "\n",
    "scores = cross_validation.cross_val_score(alg, titanic_train[predictors_w_SocialClass], titanic_train[\"Survived\"], cv=3)\n",
    "print(scores)\n",
    "print (scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg.fit(titanic_train[predictors], titanic_train[\"Survived\"])\n",
    "\n",
    "predictions = alg.predict(titanic_test[predictors])\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset.\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": titanic_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "\n",
    "submission.to_csv(\"random_forest_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ready to submit this first version to see how it does. It did pretty average, I did worse than my iteration 1. Before I managed to acquire around 0.82 with a combination of the random forest model and embarkment ports. Somehow, today I managed to get 0.75598 on kaggle. \n",
    "\n",
    "I guess I just don't understand how this did not enhance my score from last time. No this does not make sense. Last time I was just messing around and got high values. This time I actually tried to think about likely cases and my score got worse. Taking away from this, its easy to note which values should be weighted more than the others, but its difficult to think about how much more. \n",
    "\n",
    "Overrall, using the random forrest model and these two recodes, I can predict 81.70% of the training data and 75.59% of the test data. I understand the process of acquiring data, cleaning data, exploring the data, developing theories and models from the looking and the data, and then logically coming up with solutions or interesting things to predict. In my case, I thought SVM  would be an ideal model. I was hoping SVM would work because that would be super cool to explore.I guess it just make sense that no matter how much I keep tweaking my data here, I do not seem to get a change. Perhaps this is because I cannot see if I am overfitting things. \n",
    "\n",
    "Future explorations to enhance the death predictions including getting a map of the titanic and researching which side went down first. I think that the people least prepared to react, at least some of them, died instantly into the cold water that way. It would also be interesting to find out how many boats exactly they had on their boat and piece together how many people per boat and such. I would have also wanted to do more with age ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
